# languageModels

### Weight-dropped LSTM (DropConnect)
  - [Regularization of Neural Networks using DropConnect](https://cs.nyu.edu/~wanli/dropc/dropc.pdf)
  - Instead of setting randomly selected subset of activations to zero, set a randomly selected subset of weights within a network to zero.
### NT-ASGD 
### Extendend regularization techniques 
#### Variable length backpropogation sequences 
#### Variational dropout 
#### Embedding dropout 
#### Weight tying 
#### Independent embedding size and hidden size 
#### Activation Regulatization (AR) and Temporal Activation Regulaization (TAR)
